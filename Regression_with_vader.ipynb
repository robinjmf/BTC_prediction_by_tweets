{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10cdd34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.2-cp310-cp310-win_amd64.whl (10.6 MB)\n",
      "     --------------------------------------- 10.6/10.6 MB 97.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "     ------------------------------------- 503.5/503.5 KB 99.0 kB/s eta 0:00:00\n",
      "Collecting numpy>=1.21.0\n",
      "  Downloading numpy-1.22.3-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "     --------------------------------------- 14.7/14.7 MB 83.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\robin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.22.3 pandas-1.4.2 pytz-2022.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18484d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146258b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv('tweet_labeled.csv')\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_[[\"date\" , \"text\", \"label_1D\" ]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ecb66f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tweets \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      2\u001b[0m tweets[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m11\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "tweets = df[\"text\"].tolist()\n",
    "tweets[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969844b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m tweets_cleaned \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#Read the tweets one by one and process it\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(\u001b[43mtweets\u001b[49m)):\n\u001b[0;32m     19\u001b[0m     processedTweet \u001b[38;5;241m=\u001b[39m processTweet(tweets[i])\n\u001b[0;32m     20\u001b[0m     tweets_cleaned\u001b[38;5;241m.\u001b[39mappend(processedTweet)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "def processTweet(tweet): #start process_tweet\n",
    "    # process the tweets\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)#trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet\n",
    "#end\n",
    "tweets_cleaned = []\n",
    "#Read the tweets one by one and process it\n",
    "for i in range (0,len(tweets)):\n",
    "    processedTweet = processTweet(tweets[i])\n",
    "    tweets_cleaned.append(processedTweet)\n",
    "print(len(tweets_cleaned))\n",
    "tweets_cleaned[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac16b76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label_1D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>2‚É£ debunking 9 bitcoin myths by AT_USER ‚¨áÔ∏è cry...</td>\n",
       "      <td>0.068038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>üìñ weekend read üìñ keen to learn about crypto as...</td>\n",
       "      <td>0.068038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>4‚É£ üéôÔ∏è bloomberg lp cryptooutlook 2021 with AT_...</td>\n",
       "      <td>0.068038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>reddcoin rdd AT_USER to the moon altcoin turnr...</td>\n",
       "      <td>0.068038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>5‚É£ blockchain 50 2021 by AT_USER AT_USER , AT_...</td>\n",
       "      <td>0.068038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284908</th>\n",
       "      <td>2022-02-09 23:59:00</td>\n",
       "      <td>any recommendations for a site that can do wha...</td>\n",
       "      <td>-0.019778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284909</th>\n",
       "      <td>2022-02-09 23:59:00</td>\n",
       "      <td>AT_USER running out of bitcoin</td>\n",
       "      <td>-0.019778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284910</th>\n",
       "      <td>2022-02-09 23:59:00</td>\n",
       "      <td>i wish you success in this valuable campaign. ...</td>\n",
       "      <td>-0.019778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284911</th>\n",
       "      <td>2022-02-09 23:59:00</td>\n",
       "      <td>wish i had more money for crypto... bitcoin</td>\n",
       "      <td>-0.019778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284912</th>\n",
       "      <td>2022-02-09 23:59:00</td>\n",
       "      <td>üëã who's someone in the bitcoin, blockchain, cr...</td>\n",
       "      <td>-0.019778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2284913 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "0        2021-02-05 10:52:00   \n",
       "1        2021-02-05 10:52:00   \n",
       "2        2021-02-05 10:52:00   \n",
       "3        2021-02-05 10:52:00   \n",
       "4        2021-02-05 10:52:00   \n",
       "...                      ...   \n",
       "2284908  2022-02-09 23:59:00   \n",
       "2284909  2022-02-09 23:59:00   \n",
       "2284910  2022-02-09 23:59:00   \n",
       "2284911  2022-02-09 23:59:00   \n",
       "2284912  2022-02-09 23:59:00   \n",
       "\n",
       "                                                      text  label_1D  \n",
       "0        2‚É£ debunking 9 bitcoin myths by AT_USER ‚¨áÔ∏è cry...  0.068038  \n",
       "1        üìñ weekend read üìñ keen to learn about crypto as...  0.068038  \n",
       "2        4‚É£ üéôÔ∏è bloomberg lp cryptooutlook 2021 with AT_...  0.068038  \n",
       "3        reddcoin rdd AT_USER to the moon altcoin turnr...  0.068038  \n",
       "4        5‚É£ blockchain 50 2021 by AT_USER AT_USER , AT_...  0.068038  \n",
       "...                                                    ...       ...  \n",
       "2284908  any recommendations for a site that can do wha... -0.019778  \n",
       "2284909                     AT_USER running out of bitcoin -0.019778  \n",
       "2284910  i wish you success in this valuable campaign. ... -0.019778  \n",
       "2284911        wish i had more money for crypto... bitcoin -0.019778  \n",
       "2284912  üëã who's someone in the bitcoin, blockchain, cr... -0.019778  \n",
       "\n",
       "[2284913 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.assign(text=tweets_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cb5613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2284913, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2‚É£ debunking 9 bitcoin myths by AT_USER ‚¨áÔ∏è cry...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üìñ weekend read üìñ keen to learn about crypto as...</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4‚É£ üéôÔ∏è bloomberg lp cryptooutlook 2021 with AT_...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reddcoin rdd AT_USER to the moon altcoin turnr...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5‚É£ blockchain 50 2021 by AT_USER AT_USER , AT_...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bitcoin and eth both have bullish setups for a...</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$perl 0.06. i have insisted that since 0.02 it...</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amazing üòç monopoly crypto cryptocurrency crypt...</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AT_USER $juld $bnb binance bsc binancesmartcha...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>amazoncoin = 100% love üíö üëâüëâ URL $ama amazoncoi...</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bitcoin braces for $48,000 as inverse head-and...</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweets  positive  negative  \\\n",
       "0   2‚É£ debunking 9 bitcoin myths by AT_USER ‚¨áÔ∏è cry...     0.000       0.0   \n",
       "1   üìñ weekend read üìñ keen to learn about crypto as...     0.183       0.0   \n",
       "2   4‚É£ üéôÔ∏è bloomberg lp cryptooutlook 2021 with AT_...     0.000       0.0   \n",
       "3   reddcoin rdd AT_USER to the moon altcoin turnr...     0.000       0.0   \n",
       "4   5‚É£ blockchain 50 2021 by AT_USER AT_USER , AT_...     0.000       0.0   \n",
       "5   bitcoin and eth both have bullish setups for a...     0.151       0.0   \n",
       "6   $perl 0.06. i have insisted that since 0.02 it...     0.091       0.0   \n",
       "7   amazing üòç monopoly crypto cryptocurrency crypt...     0.362       0.0   \n",
       "8   AT_USER $juld $bnb binance bsc binancesmartcha...     0.000       0.0   \n",
       "9   amazoncoin = 100% love üíö üëâüëâ URL $ama amazoncoi...     0.307       0.0   \n",
       "10  bitcoin braces for $48,000 as inverse head-and...     0.144       0.0   \n",
       "\n",
       "    neutral  \n",
       "0     1.000  \n",
       "1     0.817  \n",
       "2     1.000  \n",
       "3     1.000  \n",
       "4     1.000  \n",
       "5     0.849  \n",
       "6     0.909  \n",
       "7     0.638  \n",
       "8     1.000  \n",
       "9     0.693  \n",
       "10    0.856  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "def getCoumpoundScore(Tweets):\n",
    "    pos = vader.polarity_scores(Tweets)['pos']\n",
    "    neg = vader.polarity_scores(Tweets)['neg']\n",
    "    neu = vader.polarity_scores(Tweets)['neu']\n",
    "    #score = vader.polarity_scores(Tweets)['compound']\n",
    "    return pos, neg, neu \n",
    "pos = []\n",
    "neg = []\n",
    "neu = []\n",
    "#Read the tweets one by one and get the sentiment score\n",
    "for i in range (0,len(tweets_cleaned)):\n",
    "    tweets_pos, tweets_neg, tweets_neu = getCoumpoundScore(tweets_cleaned[i])\n",
    "    pos.append(tweets_pos)\n",
    "    neg.append(tweets_neg)\n",
    "    neu.append(tweets_neu)\n",
    "#store the tweet with polarity score in a dictionary\n",
    "df_scores ={\"tweets\": tweets_cleaned, \"positive\" : pos, \"negative\" : neg, \"neutral\" : neu}\n",
    "df_scores = DataFrame(df_scores)#transfer into a dataframe\n",
    "print(df_scores.shape)\n",
    "df_scores.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc9b6527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2284913, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label_1D</th>\n",
       "      <th>tweets</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>2‚É£ debunking 9 bitcoin myths by AT_USER ‚¨áÔ∏è cry...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>üìñ weekend read üìñ keen to learn about crypto as...</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>4‚É£ üéôÔ∏è bloomberg lp cryptooutlook 2021 with AT_...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>reddcoin rdd AT_USER to the moon altcoin turnr...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-05 10:52:00</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>5‚É£ blockchain 50 2021 by AT_USER AT_USER , AT_...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-05 10:53:00</td>\n",
       "      <td>0.069270</td>\n",
       "      <td>bitcoin and eth both have bullish setups for a...</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-02-05 10:54:00</td>\n",
       "      <td>0.067211</td>\n",
       "      <td>$perl 0.06. i have insisted that since 0.02 it...</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-05 10:57:00</td>\n",
       "      <td>0.068002</td>\n",
       "      <td>amazing üòç monopoly crypto cryptocurrency crypt...</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-02-05 10:58:00</td>\n",
       "      <td>0.068632</td>\n",
       "      <td>AT_USER $juld $bnb binance bsc binancesmartcha...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-02-05 10:58:00</td>\n",
       "      <td>0.068632</td>\n",
       "      <td>amazoncoin = 100% love üíö üëâüëâ URL $ama amazoncoi...</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  label_1D  \\\n",
       "0  2021-02-05 10:52:00  0.068038   \n",
       "1  2021-02-05 10:52:00  0.068038   \n",
       "2  2021-02-05 10:52:00  0.068038   \n",
       "3  2021-02-05 10:52:00  0.068038   \n",
       "4  2021-02-05 10:52:00  0.068038   \n",
       "5  2021-02-05 10:53:00  0.069270   \n",
       "6  2021-02-05 10:54:00  0.067211   \n",
       "7  2021-02-05 10:57:00  0.068002   \n",
       "8  2021-02-05 10:58:00  0.068632   \n",
       "9  2021-02-05 10:58:00  0.068632   \n",
       "\n",
       "                                              tweets  positive  negative  \\\n",
       "0  2‚É£ debunking 9 bitcoin myths by AT_USER ‚¨áÔ∏è cry...     0.000       0.0   \n",
       "1  üìñ weekend read üìñ keen to learn about crypto as...     0.183       0.0   \n",
       "2  4‚É£ üéôÔ∏è bloomberg lp cryptooutlook 2021 with AT_...     0.000       0.0   \n",
       "3  reddcoin rdd AT_USER to the moon altcoin turnr...     0.000       0.0   \n",
       "4  5‚É£ blockchain 50 2021 by AT_USER AT_USER , AT_...     0.000       0.0   \n",
       "5  bitcoin and eth both have bullish setups for a...     0.151       0.0   \n",
       "6  $perl 0.06. i have insisted that since 0.02 it...     0.091       0.0   \n",
       "7  amazing üòç monopoly crypto cryptocurrency crypt...     0.362       0.0   \n",
       "8  AT_USER $juld $bnb binance bsc binancesmartcha...     0.000       0.0   \n",
       "9  amazoncoin = 100% love üíö üëâüëâ URL $ama amazoncoi...     0.307       0.0   \n",
       "\n",
       "   neutral  \n",
       "0    1.000  \n",
       "1    0.817  \n",
       "2    1.000  \n",
       "3    1.000  \n",
       "4    1.000  \n",
       "5    0.849  \n",
       "6    0.909  \n",
       "7    0.638  \n",
       "8    1.000  \n",
       "9    0.693  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.concat([df,df_scores],axis=1).reset_index(drop=True)\n",
    "merged_data = merged_data.drop('text',axis=1)\n",
    "print(merged_data.shape)\n",
    "merged_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87366559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_data[['positive', 'negative', 'neutral']],merged_data['label_1D'], test_size=0.005, train_size=0.025, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4700031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6be9ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "dim = X_train.shape[1]\n",
    "# define our MLP network\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1607358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def custom_MAE (y_true, y_pred):\n",
    "#    \n",
    "#    df_[MAE] = np.where((np.sign(df_[predict])) == np.sign(df_[label]) , 20*mean_absolute_error(df_[label],df_[predict])\n",
    "#                       , 60*mean_absolute_error(df_[label],df_[predict]))\n",
    "#    result = df_[MAE].mean()               \n",
    "#    return result\n",
    "\n",
    "def custom_MAE(y_true, y_pred):\n",
    " \n",
    "    loss = np.where((np.sign(y_pred)) == np.sign(y_true) , 20*mean_absolute_error(y_true, y_pred)\n",
    "                       , 60*mean_absolute_error(y_true, y_pred))    \n",
    "    result = loss.mean()       \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77ba228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\AppData\\Local\\Temp/ipykernel_12420/2137811338.py:10: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  loss = np.where((np.sign(y_pred)) == np.sign(y_true) , 20*mean_absolute_error(y_true, y_pred)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12420/3679387964.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcustom_MAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12420/2137811338.py\u001b[0m in \u001b[0;36mcustom_MAE\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcustom_MAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     loss = np.where((np.sign(y_pred)) == np.sign(y_true) , 20*mean_absolute_error(y_true, y_pred)\n\u001b[0m\u001b[0;32m     11\u001b[0m                        , 60*mean_absolute_error(y_true, y_pred))    \n\u001b[0;32m     12\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\robin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\robin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__eq__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__ne__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\robin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   4978\u001b[0m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4980\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4982\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_logical_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\robin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_construct_result\u001b[1;34m(self, result, name)\u001b[0m\n\u001b[0;32m   2761\u001b[0m         \u001b[1;31m# We do not pass dtype to ensure that the Series constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2762\u001b[0m         \u001b[1;31m#  does inference in the case where `result` has object-dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2763\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2764\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\robin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    362\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\robin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "custom_MAE(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56f5b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\robin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"custom_MAE\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0aef942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 32        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf2e62bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5713/5713 [==============================] - 22s 3ms/step - loss: 138.1213 - val_loss: 128.3471\n",
      "Epoch 2/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 141.2204 - val_loss: 113.6118\n",
      "Epoch 3/200\n",
      "5713/5713 [==============================] - 13s 2ms/step - loss: 135.7356 - val_loss: 101.4569\n",
      "Epoch 4/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 137.9907 - val_loss: 103.9696\n",
      "Epoch 5/200\n",
      "5713/5713 [==============================] - 13s 2ms/step - loss: 136.9614 - val_loss: 108.1653\n",
      "Epoch 6/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 134.0988 - val_loss: 106.2270\n",
      "Epoch 7/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 132.5190 - val_loss: 116.8002\n",
      "Epoch 8/200\n",
      "5713/5713 [==============================] - 12s 2ms/step - loss: 133.7870 - val_loss: 252.3346\n",
      "Epoch 9/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 135.8148 - val_loss: 245.7822\n",
      "Epoch 10/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 131.9589 - val_loss: 339.6650\n",
      "Epoch 11/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 128.7600 - val_loss: 138.5956\n",
      "Epoch 12/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 127.4706 - val_loss: 114.3959\n",
      "Epoch 13/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 129.4031 - val_loss: 110.5008\n",
      "Epoch 14/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 130.7076 - val_loss: 102.1480\n",
      "Epoch 15/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 129.0342 - val_loss: 123.9151\n",
      "Epoch 16/200\n",
      "5713/5713 [==============================] - 12s 2ms/step - loss: 127.0182 - val_loss: 104.8959\n",
      "Epoch 17/200\n",
      "5713/5713 [==============================] - 12s 2ms/step - loss: 125.7854 - val_loss: 100.9965\n",
      "Epoch 18/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 124.5739 - val_loss: 110.1977\n",
      "Epoch 19/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 126.8093 - val_loss: 100.7971\n",
      "Epoch 20/200\n",
      "5713/5713 [==============================] - 12s 2ms/step - loss: 126.7278 - val_loss: 100.6537\n",
      "Epoch 21/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 125.6091 - val_loss: 121.2955\n",
      "Epoch 22/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 124.9790 - val_loss: 295.1237\n",
      "Epoch 23/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 125.0507 - val_loss: 100.2101\n",
      "Epoch 24/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 121.3569 - val_loss: 149.6736\n",
      "Epoch 25/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 122.5849 - val_loss: 119.6972\n",
      "Epoch 26/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 124.8078 - val_loss: 104.8189\n",
      "Epoch 27/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 123.2229 - val_loss: 147.1613\n",
      "Epoch 28/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 120.6408 - val_loss: 117.3263\n",
      "Epoch 29/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 124.8072 - val_loss: 106.1554\n",
      "Epoch 30/200\n",
      "5713/5713 [==============================] - 13s 2ms/step - loss: 121.6524 - val_loss: 103.3965\n",
      "Epoch 31/200\n",
      "5713/5713 [==============================] - 18s 3ms/step - loss: 121.3835 - val_loss: 114.0153\n",
      "Epoch 32/200\n",
      "5713/5713 [==============================] - 13s 2ms/step - loss: 117.8555 - val_loss: 107.1939\n",
      "Epoch 33/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 121.0312 - val_loss: 100.2226\n",
      "Epoch 34/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 120.1975 - val_loss: 102.8359\n",
      "Epoch 35/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 119.3666 - val_loss: 102.6749\n",
      "Epoch 36/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 119.1607 - val_loss: 100.2503\n",
      "Epoch 37/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 119.8862 - val_loss: 101.3259\n",
      "Epoch 38/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 117.4084 - val_loss: 100.4360\n",
      "Epoch 39/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 118.8029 - val_loss: 114.4489\n",
      "Epoch 40/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 117.5392 - val_loss: 112.6424\n",
      "Epoch 41/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 119.2866 - val_loss: 111.4762\n",
      "Epoch 42/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 117.0827 - val_loss: 341.7289\n",
      "Epoch 43/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 119.8555 - val_loss: 100.8240\n",
      "Epoch 44/200\n",
      "5713/5713 [==============================] - 9s 1ms/step - loss: 116.8489 - val_loss: 101.3331\n",
      "Epoch 45/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 116.8881 - val_loss: 104.3622\n",
      "Epoch 46/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 117.4738 - val_loss: 212.4361\n",
      "Epoch 47/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 115.4218 - val_loss: 163.7524\n",
      "Epoch 48/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 115.5365 - val_loss: 109.1152\n",
      "Epoch 49/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 116.0364 - val_loss: 101.1483\n",
      "Epoch 50/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 115.0707 - val_loss: 102.6429\n",
      "Epoch 51/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 115.6650 - val_loss: 107.9259\n",
      "Epoch 52/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 116.1501 - val_loss: 101.7530\n",
      "Epoch 53/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 113.9520 - val_loss: 111.5871\n",
      "Epoch 54/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 114.9506 - val_loss: 102.4282\n",
      "Epoch 55/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 114.7160 - val_loss: 276.5059\n",
      "Epoch 56/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 116.0837 - val_loss: 102.0756\n",
      "Epoch 57/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 115.3214 - val_loss: 101.6235\n",
      "Epoch 58/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 117.3591 - val_loss: 127.7146\n",
      "Epoch 59/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 112.5041 - val_loss: 100.6219\n",
      "Epoch 60/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 115.3628 - val_loss: 114.8702\n",
      "Epoch 61/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 113.4261 - val_loss: 103.7095\n",
      "Epoch 62/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 114.9711 - val_loss: 101.7145\n",
      "Epoch 63/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 114.8383 - val_loss: 105.2982\n",
      "Epoch 64/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 112.0886 - val_loss: 267.9566\n",
      "Epoch 65/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 114.8263 - val_loss: 108.7033\n",
      "Epoch 66/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 112.6731 - val_loss: 118.9432\n",
      "Epoch 67/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 114.7492 - val_loss: 102.6661\n",
      "Epoch 68/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 111.6124 - val_loss: 102.5076\n",
      "Epoch 69/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 113.3294 - val_loss: 103.3601\n",
      "Epoch 70/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 112.9847 - val_loss: 105.1887\n",
      "Epoch 71/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 113.4258 - val_loss: 110.1000\n",
      "Epoch 72/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 113.4761 - val_loss: 100.9261\n",
      "Epoch 73/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 112.5507 - val_loss: 109.0752\n",
      "Epoch 74/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 111.7139 - val_loss: 111.4533\n",
      "Epoch 75/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 112.2211 - val_loss: 120.9268\n",
      "Epoch 76/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 111.5130 - val_loss: 132.0169\n",
      "Epoch 77/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 110.9573 - val_loss: 102.7026\n",
      "Epoch 78/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 112.7981 - val_loss: 101.5223\n",
      "Epoch 79/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 111.3192 - val_loss: 105.5615\n",
      "Epoch 80/200\n",
      "5713/5713 [==============================] - 9s 1ms/step - loss: 110.8249 - val_loss: 100.3229\n",
      "Epoch 81/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 110.8433 - val_loss: 128.4934\n",
      "Epoch 82/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 111.2698 - val_loss: 104.7871\n",
      "Epoch 83/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 110.9115 - val_loss: 179.7044\n",
      "Epoch 84/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 111.2250 - val_loss: 101.8509\n",
      "Epoch 85/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 111.4268 - val_loss: 106.7447\n",
      "Epoch 86/200\n",
      "5713/5713 [==============================] - 12s 2ms/step - loss: 110.7478 - val_loss: 110.9672\n",
      "Epoch 87/200\n",
      "5713/5713 [==============================] - 12s 2ms/step - loss: 111.3281 - val_loss: 135.7235\n",
      "Epoch 88/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 110.8211 - val_loss: 101.1794\n",
      "Epoch 89/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 111.7197 - val_loss: 101.3454\n",
      "Epoch 90/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 109.7445 - val_loss: 234.9334\n",
      "Epoch 91/200\n",
      "5713/5713 [==============================] - 12s 2ms/step - loss: 111.2809 - val_loss: 102.7412\n",
      "Epoch 92/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 110.6701 - val_loss: 101.4473\n",
      "Epoch 93/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 109.7925 - val_loss: 102.0277\n",
      "Epoch 94/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 109.8556 - val_loss: 100.3982\n",
      "Epoch 95/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 108.2200 - val_loss: 108.4722\n",
      "Epoch 96/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 111.5139 - val_loss: 109.5481\n",
      "Epoch 97/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 109.2792 - val_loss: 101.6119\n",
      "Epoch 98/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 109.7003 - val_loss: 102.6248\n",
      "Epoch 99/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 110.9456 - val_loss: 138.0384\n",
      "Epoch 100/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 109.0301 - val_loss: 115.4140\n",
      "Epoch 101/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 110.7519 - val_loss: 103.4972\n",
      "Epoch 102/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 109.0186 - val_loss: 100.2339\n",
      "Epoch 103/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 109.6710 - val_loss: 101.8348\n",
      "Epoch 104/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 111.1238 - val_loss: 103.5721\n",
      "Epoch 105/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 108.4133 - val_loss: 134.5509\n",
      "Epoch 106/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 109.8750 - val_loss: 114.5767\n",
      "Epoch 107/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 108.7186 - val_loss: 101.9060\n",
      "Epoch 108/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 109.1004 - val_loss: 122.7955\n",
      "Epoch 109/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 110.1339 - val_loss: 104.4802\n",
      "Epoch 110/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 108.9147 - val_loss: 104.4500\n",
      "Epoch 111/200\n",
      "5713/5713 [==============================] - 9s 1ms/step - loss: 109.5821 - val_loss: 104.7905\n",
      "Epoch 112/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 110.1674 - val_loss: 120.4394\n",
      "Epoch 113/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 109.4134 - val_loss: 104.2373\n",
      "Epoch 114/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 107.3476 - val_loss: 102.7338\n",
      "Epoch 115/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 109.0751 - val_loss: 124.4107\n",
      "Epoch 116/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 108.6282 - val_loss: 122.2779\n",
      "Epoch 117/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 108.3916 - val_loss: 211.7344\n",
      "Epoch 118/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 110.0635 - val_loss: 102.1842\n",
      "Epoch 119/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 108.3888 - val_loss: 104.2314\n",
      "Epoch 120/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 108.5540 - val_loss: 107.6311\n",
      "Epoch 121/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 108.2776 - val_loss: 114.4293\n",
      "Epoch 122/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 108.7644 - val_loss: 100.0673\n",
      "Epoch 123/200\n",
      "5713/5713 [==============================] - 12s 2ms/step - loss: 108.3240 - val_loss: 178.9715\n",
      "Epoch 124/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 108.7665 - val_loss: 102.2576\n",
      "Epoch 125/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 108.2858 - val_loss: 166.9712\n",
      "Epoch 126/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 108.0040 - val_loss: 100.1775\n",
      "Epoch 127/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 108.6932 - val_loss: 100.9535\n",
      "Epoch 128/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 108.0901 - val_loss: 149.7278\n",
      "Epoch 129/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 107.7287 - val_loss: 109.9193\n",
      "Epoch 130/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 107.3175 - val_loss: 106.2197\n",
      "Epoch 131/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 108.8197 - val_loss: 174.6551\n",
      "Epoch 132/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 107.0676 - val_loss: 100.2735\n",
      "Epoch 133/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 108.3002 - val_loss: 148.8500\n",
      "Epoch 134/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 107.0415 - val_loss: 103.1145\n",
      "Epoch 135/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 107.9654 - val_loss: 104.7680\n",
      "Epoch 136/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 107.9277 - val_loss: 101.4261\n",
      "Epoch 137/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 108.1108 - val_loss: 100.7354\n",
      "Epoch 138/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 107.4325 - val_loss: 103.1375\n",
      "Epoch 139/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 108.2135 - val_loss: 117.1076\n",
      "Epoch 140/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 107.5037 - val_loss: 100.1877\n",
      "Epoch 141/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 106.9884 - val_loss: 114.3742\n",
      "Epoch 142/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 107.4873 - val_loss: 102.3542\n",
      "Epoch 143/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 107.2131 - val_loss: 103.8187\n",
      "Epoch 144/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 107.2583 - val_loss: 100.9303\n",
      "Epoch 145/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 107.1137 - val_loss: 103.0398\n",
      "Epoch 146/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 106.6802 - val_loss: 101.3970\n",
      "Epoch 147/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 106.6079 - val_loss: 106.1787\n",
      "Epoch 148/200\n",
      "5713/5713 [==============================] - 12s 2ms/step - loss: 107.7957 - val_loss: 100.3075\n",
      "Epoch 149/200\n",
      "5713/5713 [==============================] - 13s 2ms/step - loss: 107.0872 - val_loss: 176.9446\n",
      "Epoch 150/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 106.8638 - val_loss: 131.5861\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.8546 - val_loss: 100.4219\n",
      "Epoch 152/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.2451 - val_loss: 194.2187\n",
      "Epoch 153/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.9382 - val_loss: 103.5807\n",
      "Epoch 154/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 107.1846 - val_loss: 104.4560\n",
      "Epoch 155/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 107.6365 - val_loss: 103.3406\n",
      "Epoch 156/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.8400 - val_loss: 114.2971\n",
      "Epoch 157/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 107.1531 - val_loss: 100.1961\n",
      "Epoch 158/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 107.1517 - val_loss: 102.1361\n",
      "Epoch 159/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 106.6150 - val_loss: 125.2696\n",
      "Epoch 160/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.3262 - val_loss: 103.0117\n",
      "Epoch 161/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 107.0266 - val_loss: 105.7396\n",
      "Epoch 162/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.8334 - val_loss: 101.0716\n",
      "Epoch 163/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.4522 - val_loss: 118.8527\n",
      "Epoch 164/200\n",
      "5713/5713 [==============================] - 11s 2ms/step - loss: 105.8611 - val_loss: 157.0367\n",
      "Epoch 165/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.1874 - val_loss: 103.8645\n",
      "Epoch 166/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.5684 - val_loss: 122.8719\n",
      "Epoch 167/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.9528 - val_loss: 171.8382\n",
      "Epoch 168/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.5798 - val_loss: 102.4817\n",
      "Epoch 169/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.1667 - val_loss: 175.0782\n",
      "Epoch 170/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.2710 - val_loss: 101.3321\n",
      "Epoch 171/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.5693 - val_loss: 131.3542\n",
      "Epoch 172/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 105.9740 - val_loss: 103.5995\n",
      "Epoch 173/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.4828 - val_loss: 102.0222\n",
      "Epoch 174/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.0208 - val_loss: 100.6185\n",
      "Epoch 175/200\n",
      "5713/5713 [==============================] - 9s 1ms/step - loss: 105.9736 - val_loss: 102.1174\n",
      "Epoch 176/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.7537 - val_loss: 102.7998\n",
      "Epoch 177/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.4007 - val_loss: 104.3850\n",
      "Epoch 178/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.6925 - val_loss: 100.0919\n",
      "Epoch 179/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.1391 - val_loss: 114.3998\n",
      "Epoch 180/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.6073 - val_loss: 126.6849\n",
      "Epoch 181/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.0952 - val_loss: 102.7303\n",
      "Epoch 182/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.8106 - val_loss: 123.8849\n",
      "Epoch 183/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.2576 - val_loss: 104.2017\n",
      "Epoch 184/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 105.7173 - val_loss: 100.6003\n",
      "Epoch 185/200\n",
      "5713/5713 [==============================] - 10s 2ms/step - loss: 105.6939 - val_loss: 109.4210\n",
      "Epoch 186/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 105.8623 - val_loss: 101.1899\n",
      "Epoch 187/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.7059 - val_loss: 100.3679\n",
      "Epoch 188/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 106.1908 - val_loss: 120.8240\n",
      "Epoch 189/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.7196 - val_loss: 132.6409\n",
      "Epoch 190/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 104.3985 - val_loss: 107.2371\n",
      "Epoch 191/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 106.3620 - val_loss: 153.3310\n",
      "Epoch 192/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.9440 - val_loss: 110.6420\n",
      "Epoch 193/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 105.4515 - val_loss: 109.9084\n",
      "Epoch 194/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.5881 - val_loss: 101.0689\n",
      "Epoch 195/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.8608 - val_loss: 124.7309\n",
      "Epoch 196/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.3145 - val_loss: 100.7718\n",
      "Epoch 197/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.4350 - val_loss: 103.1103\n",
      "Epoch 198/200\n",
      "5713/5713 [==============================] - 8s 1ms/step - loss: 105.8759 - val_loss: 100.1371\n",
      "Epoch 199/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 105.5319 - val_loss: 101.7361\n",
      "Epoch 200/200\n",
      "5713/5713 [==============================] - 9s 2ms/step - loss: 105.3786 - val_loss: 101.7855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ad030db20>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "    epochs=200, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33fd0f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11425, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6030326c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11425,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3c2ed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. : $0.00, std : $0.04\n",
      "mean: 101.79%, std: 67.34%\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "\n",
    "# make predictions on the testing data\n",
    "preds = model.predict(X_test)\n",
    " \n",
    "# compute the difference between the *predicted* house prices and the\n",
    "# *actual* house prices, then compute the percentage difference and\n",
    "# the absolute percentage difference\n",
    "diff = preds.flatten() - y_test\n",
    "percentDiff = (diff / y_test) * 100\n",
    "absPercentDiff = np.abs(percentDiff)\n",
    " \n",
    "# compute the mean and standard deviation of the absolute percentage\n",
    "# difference\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    " \n",
    "# finally, show some statistics on our model\n",
    "locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n",
    "print(\"avg. : {}, std : {}\".format(\n",
    "    locale.currency(df[\"label_1D\"].mean(), grouping=True),\n",
    "    locale.currency(df[\"label_1D\"].std(), grouping=True)))\n",
    "print(\"mean: {:.2f}%, std: {:.2f}%\".format(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7cf1834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430278b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_MAE()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
